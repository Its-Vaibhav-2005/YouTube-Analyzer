{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05c730a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b543e552",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABLE_FILE = './data/lableHistory.csv'\n",
    "FULL_DATAFILE = './data/cleanHistory.csv'\n",
    "OUTPUTFILE = './data/fullClassified.csv'\n",
    "\n",
    "MODLE = 'models/classifier.pth'\n",
    "VECTORIZER = 'models/vectorizer.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d6edd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "np.random.seed(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77b4fb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadAndPrepData():\n",
    "    labeledDf = pd.read_csv(LABLE_FILE)\n",
    "    fullDf = pd.read_csv(FULL_DATAFILE)\n",
    "\n",
    "    labeledDf['text'] = labeledDf['title']+\" \"+labeledDf['channel'].fillna('')\n",
    "    fullDf['text'] = fullDf['title']+\" \"+fullDf['channel'].fillna('')\n",
    "\n",
    "    return labeledDf, fullDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d6bfead",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorizeData(labledDf, fullDf):\n",
    "    allText = pd.concat([labledDf['text'], fullDf['text']])\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=2000, stop_words='english')\n",
    "    vectorizer.fit(allText)\n",
    "\n",
    "    X_labeled = vectorizer.transform(labledDf['text']).toarray()\n",
    "    y_labeled = labledDf['label'].values-1\n",
    "\n",
    "    return X_labeled, y_labeled, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5f5e9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WatchHistoryClassifier(nn.Module):\n",
    "    def __init__(self, input_dim, num_classes):\n",
    "        super(WatchHistoryClassifier, self).__init__()\n",
    "\n",
    "        # Layer 1: compression to 64 features\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        # Layer 2: Output logits for classes\n",
    "        self.fc2 = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "914a399f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, y):\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "    X_train_t = torch.FloatTensor(X_train)\n",
    "    y_train_t = torch.LongTensor(y_train)\n",
    "    X_val_t = torch.FloatTensor(X_val)\n",
    "    y_val_t = torch.LongTensor(y_val)\n",
    "\n",
    "    model = WatchHistoryClassifier(input_dim=X.shape[1], num_classes=len(np.unique(y)))\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "    for epoch in range(100):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_t)\n",
    "        loss = criterion(outputs, y_train_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch+1}/100], Loss: {loss.item():.4f}')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        val_outputs = model(X_val_t)\n",
    "        _, predicted = torch.max(val_outputs.data, 1)\n",
    "        print(classification_report(y_val_t, predicted, zero_division=0))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b06f900",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictFullHistory(model, vectorizer, fullDf):\n",
    "    X_full = vectorizer.transform(fullDf['text']).toarray()\n",
    "    X_full_t = torch.FloatTensor(X_full)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_full_t)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "    fullDf['predicted_label'] = predicted.numpy()+1\n",
    "\n",
    "    CATEGORY = {\n",
    "        '1': 'Learning',\n",
    "        '2': 'Entertainment',\n",
    "        '3': 'Music',\n",
    "        '4': 'Finance',\n",
    "        '5': 'News',\n",
    "        '6': 'Others'\n",
    "    }\n",
    "\n",
    "    fullDf['category_name'] = fullDf['predicted_label'].map(CATEGORY)\n",
    "\n",
    "    return fullDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a62bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
